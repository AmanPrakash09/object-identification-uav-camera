{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e976cfe5-48b0-40a0-8011-4ce4017632ba",
   "metadata": {},
   "source": [
    "# YOLOv12 Nano COCO Benchmark\n",
    "\n",
    "### Setup Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22dca0be-1847-42b1-99da-77252cf461b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file  \n",
      "View Ultralytics Settings with 'yolo settings' or at 'C:\\Users\\amanp\\AppData\\Roaming\\yolov12\\settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "FlashAttention is not available on this device. Using scaled_dot_product_attention instead.\n",
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA/GPU available: True\n",
      "CUDA version: 12.1\n",
      "GPU name: NVIDIA GeForce GTX 1660 Ti\n",
      "CPU Cores: 12\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import psutil\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "import fiftyone.utils.torch as fout\n",
    "from fiftyone import ViewField as F\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA/GPU available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"GPU name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU Only'}\")\n",
    "print(f\"CPU Cores: {psutil.cpu_count(logical=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a270522e-f426-4d63-a51d-1721b18eec9e",
   "metadata": {},
   "source": [
    "### Configure Local COCO Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfc496db-09c4-478e-b9c6-2e4ab07e75a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images path: C:\\object-identification-uav-camera\\phase-1\\coco-dataset\\coco-2017\\validation\\data\n",
      "Annotation file: C:\\object-identification-uav-camera\\phase-1\\coco-dataset\\coco-2017\\validation\\labels.json\n",
      "Images found: 3125\n"
     ]
    }
   ],
   "source": [
    "COCO_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"coco-dataset\", \"coco-2017\"))\n",
    "\n",
    "VAL_IMAGES = os.path.join(COCO_ROOT, \"validation\", \"data\")\n",
    "VAL_ANN = os.path.join(COCO_ROOT, \"validation\", \"labels.json\")\n",
    "\n",
    "print(\"Images path:\", VAL_IMAGES)\n",
    "print(\"Annotation file:\", VAL_ANN)\n",
    "print(\"Images found:\", len(os.listdir(VAL_IMAGES)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073f120a-dac7-4505-b5fd-e4136310603a",
   "metadata": {},
   "source": [
    "### Load COCO Dataset in FiftyOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f39e5fb-9b37-401c-ba6e-c3098e6501a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:5151/?notebook=True&subscription=dba04230-61ed-40b1-aad1-bee6fd55a8e1\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2161fdcf0a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = fo.load_dataset(\"coco-val-local\")\n",
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e48ffb-abf1-4512-b8b0-bd18b0648896",
   "metadata": {},
   "source": [
    "### Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2d22340-cfe3-420c-b58b-198470b78c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading YOLOv12 Nano...\n",
      "YOLOv12 Nano initialized.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading YOLOv12 Nano...\")\n",
    "model_yolo12 = YOLO(\"yolov12n.pt\")   # Nano version\n",
    "print(\"YOLOv12 Nano initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa406e01-e277-4ceb-be98-6760db5eea6f",
   "metadata": {},
   "source": [
    "### Jetson Simulation Setup Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "535b49bc-c8ad-4889-b3f4-41f75e907b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enabling Jetson Orin Nano 8GB simulation constraints...\n",
      "\n",
      "Disabled cuDNN fast algorithms & TF32.\n",
      "CPU threads limited to 2 (Jetson-like).\n",
      "Added 4ms I/O latency per image.\n",
      "Added memory bandwidth stall of 0.8ms.\n",
      "Added 3ms GPU stall per inference (Jetson compute speed).\n",
      "GPU VRAM restricted to ~80% of your card (Jetson-equivalent usable memory).\n",
      "\n",
      "Jetson Simulation Mode READY.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Jetson Orin Nano 8GB Simulation Mode\n",
    "# ============================\n",
    "\n",
    "print(\"\\nEnabling Jetson Orin Nano 8GB simulation constraints...\\n\")\n",
    "\n",
    "# ---- 1. Disable cuDNN fast paths (Jetson uses slower kernels) ----\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "torch.backends.cudnn.allow_tf32 = False\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "print(\"Disabled cuDNN fast algorithms & TF32.\")\n",
    "\n",
    "# ---- 2. Limit CPU parallelism ----\n",
    "import os\n",
    "torch.set_num_threads(2)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"2\"\n",
    "print(\"CPU threads limited to 2 (Jetson-like).\")\n",
    "\n",
    "# ---- 3. I/O latency to mimic Jetson eMMC/SD card ----\n",
    "IO_LATENCY = 0.004  # 4 ms\n",
    "print(\"Added 4ms I/O latency per image.\")\n",
    "\n",
    "# ---- 4. Simulate Jetson memory bandwidth ----\n",
    "BANDWIDTH_LATENCY = 0.0008  # 0.8 ms\n",
    "print(\"Added memory bandwidth stall of 0.8ms.\")\n",
    "\n",
    "# ---- 5. Simulated GPU compute stall ----\n",
    "# Jetson Orin Nano runs ~2–4× slower than GTX 1660 Ti for transformer models\n",
    "GPU_STALL = 0.003  # 3 ms (tuneable)\n",
    "print(\"Added 3ms GPU stall per inference (Jetson compute speed).\")\n",
    "\n",
    "# ---- 6. Constrain VRAM usage ----\n",
    "torch.cuda.set_per_process_memory_fraction(0.80)\n",
    "print(\"GPU VRAM restricted to ~80% of your card (Jetson-equivalent usable memory).\")\n",
    "\n",
    "print(\"\\nJetson Simulation Mode READY.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6f5801-fd43-4b64-a90f-e9e56b416117",
   "metadata": {},
   "source": [
    "### Need to Map COCO Classes to IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1565a796-b7d4-42c5-a51b-cc243e5f501d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1, 1: 2, 2: 3, 3: 4, 4: 5, 5: 6, 6: 7, 7: 8, 8: 9, 9: 10, 10: 11, 11: 13, 12: 14, 13: 15, 14: 16, 15: 17, 16: 18, 17: 19, 18: 20, 19: 21, 20: 22, 21: 23, 22: 24, 23: 25, 24: 27, 25: 28, 26: 31, 27: 32, 28: 33, 29: 34, 30: 35, 31: 36, 32: 37, 33: 38, 34: 39, 35: 40, 36: 41, 37: 42, 38: 43, 39: 44, 40: 46, 41: 47, 42: 48, 43: 49, 44: 50, 45: 51, 46: 52, 47: 53, 48: 54, 49: 55, 50: 56, 51: 57, 52: 58, 53: 59, 54: 60, 55: 61, 56: 62, 57: 63, 58: 64, 59: 65, 60: 67, 61: 70, 62: 72, 63: 73, 64: 74, 65: 75, 66: 76, 67: 77, 68: 78, 69: 79, 70: 80, 71: 81, 72: 82, 73: 84, 74: 85, 75: 86, 76: 87, 77: 88, 78: 89, 79: 90}\n"
     ]
    }
   ],
   "source": [
    "# Build COCO name → COCO ID mapping (for the 9-class subset)\n",
    "coco_name_to_id = {cat[\"name\"]: cat[\"id\"] for cat in coco_data[\"categories\"]}\n",
    "\n",
    "# YOLO name mapping: index → class name\n",
    "yolo_names = model_yolo12.names  # e.g. {0:'person', 1:'bicycle', ...}\n",
    "\n",
    "# Build YOLO → COCO category ID mapping but ONLY for your 9 classes\n",
    "yolo_to_coco = {}\n",
    "\n",
    "for yolo_idx, class_name in yolo_names.items():\n",
    "    if class_name in coco_name_to_id:   # keep only the 9 classes\n",
    "        yolo_to_coco[yolo_idx] = coco_name_to_id[class_name]\n",
    "\n",
    "print(yolo_to_coco)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c83cd8e-7e9e-4c88-b33f-6ed35598af46",
   "metadata": {},
   "source": [
    "### Inference Loop with Jestson Nano 8GB Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae99ffaa-d52f-4483-a5a6-a04675ce3cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Jetson-simulated YOLOv12 Nano inference...\n",
      "YOLO → COCO mapping used: {0: 1, 1: 2, 2: 3, 3: 4, 4: 5, 5: 6, 6: 7, 7: 8, 8: 9, 9: 10, 10: 11, 11: 13, 12: 14, 13: 15, 14: 16, 15: 17, 16: 18, 17: 19, 18: 20, 19: 21, 20: 22, 21: 23, 22: 24, 23: 25, 24: 27, 25: 28, 26: 31, 27: 32, 28: 33, 29: 34, 30: 35, 31: 36, 32: 37, 33: 38, 34: 39, 35: 40, 36: 41, 37: 42, 38: 43, 39: 44, 40: 46, 41: 47, 42: 48, 43: 49, 44: 50, 45: 51, 46: 52, 47: 53, 48: 54, 49: 55, 50: 56, 51: 57, 52: 58, 53: 59, 54: 60, 55: 61, 56: 62, 57: 63, 58: 64, 59: 65, 60: 67, 61: 70, 62: 72, 63: 73, 64: 74, 65: 75, 66: 76, 67: 77, 68: 78, 69: 79, 70: 80, 71: 81, 72: 82, 73: 84, 74: 85, 75: 86, 76: 87, 77: 88, 78: 89, 79: 90}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3125/3125 [05:37<00:00,  9.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jetson-simulated YOLOv12 Nano inference complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"Running Jetson-simulated YOLOv12 Nano inference...\")\n",
    "\n",
    "preds_json_yolo12_jetson = []\n",
    "image_filenames = os.listdir(VAL_IMAGES)\n",
    "\n",
    "with open(VAL_ANN, 'r') as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "# Build mappings\n",
    "coco_name_to_id = {cat[\"name\"]: cat[\"id\"] for cat in coco_data[\"categories\"]}\n",
    "yolo_names = model_yolo12.names\n",
    "\n",
    "# YOLO index → COCO category ID (only 9 classes)\n",
    "yolo_to_coco = {\n",
    "    yolo_idx: coco_name_to_id[class_name]\n",
    "    for yolo_idx, class_name in yolo_names.items()\n",
    "    if class_name in coco_name_to_id\n",
    "}\n",
    "\n",
    "print(\"YOLO → COCO mapping used:\", yolo_to_coco)\n",
    "\n",
    "image_id_map = {img[\"file_name\"]: img[\"id\"] for img in coco_data[\"images\"]}\n",
    "\n",
    "for filename in tqdm(image_filenames):\n",
    "    time.sleep(IO_LATENCY)\n",
    "\n",
    "    img_path = os.path.join(VAL_IMAGES, filename)\n",
    "\n",
    "    # Load original resolution (do NOT resize!)\n",
    "    with Image.open(img_path) as im:\n",
    "        if im.mode != \"RGB\":\n",
    "            im = im.convert(\"RGB\")\n",
    "        temp_path = \"temp_y12.jpg\"\n",
    "        im.save(temp_path)\n",
    "\n",
    "    time.sleep(BANDWIDTH_LATENCY)\n",
    "    time.sleep(GPU_STALL)\n",
    "\n",
    "    results = model_yolo12.predict(temp_path, conf=0.001, verbose=False)\n",
    "    det = results[0]\n",
    "    image_id = image_id_map[filename]\n",
    "\n",
    "    if det.boxes is not None:\n",
    "        for b in det.boxes:\n",
    "            cls_id = int(b.cls)\n",
    "\n",
    "            # Skip detections NOT in our 9-class subset\n",
    "            if cls_id not in yolo_to_coco:\n",
    "                continue\n",
    "\n",
    "            coco_id = yolo_to_coco[cls_id]\n",
    "\n",
    "            x1, y1, x2, y2 = b.xyxy.cpu().numpy()[0]\n",
    "            w = x2 - x1\n",
    "            h = y2 - y1\n",
    "\n",
    "            preds_json_yolo12_jetson.append({\n",
    "                \"image_id\": image_id,\n",
    "                \"category_id\": coco_id,    # FIXED\n",
    "                \"score\": float(b.conf),\n",
    "                \"bbox\": [float(x1), float(y1), float(w), float(h)]\n",
    "            })\n",
    "\n",
    "with open(\"predictions_yolo12_jetson.json\", \"w\") as f:\n",
    "    json.dump(preds_json_yolo12_jetson, f)\n",
    "\n",
    "print(\"Jetson-simulated YOLOv12 Nano inference complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c07e44-e763-4d59-a2f9-293e27cbdb45",
   "metadata": {},
   "source": [
    "### COCO Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85eb529b-abb5-424c-99ee-895b27e66ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running COCO evaluation for Jetson-simulated YOLOv12 Nano...\n",
      "loading annotations into memory...\n",
      "Done (t=1.27s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=2.77s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=30.41s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.59s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.323\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.469\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.348\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.163\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.394\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.562\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.263\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.438\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.489\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.292\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.581\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.720\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "print(\"Running COCO evaluation for Jetson-simulated YOLOv12 Nano...\")\n",
    "\n",
    "coco_gt = COCO(VAL_ANN)\n",
    "coco_dt_yolo12_jetson = coco_gt.loadRes(\"predictions_yolo12_jetson.json\")\n",
    "\n",
    "coco_eval_yolo12_jetson = COCOeval(coco_gt, coco_dt_yolo12_jetson, \"bbox\")\n",
    "coco_eval_yolo12_jetson.evaluate()\n",
    "coco_eval_yolo12_jetson.accumulate()\n",
    "coco_eval_yolo12_jetson.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c58853cf-9761-4507-823c-108b1d13e902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### YOLOv12 Nano (Jetson-Simulated) Accuracy Metrics\n",
      "\n",
      "mAP@50:95: 0.323\n",
      "mAP@50:    0.469\n",
      "\n",
      "Precision (COCO-based): 0.469\n",
      "Recall    (COCO-based): 0.693\n",
      "F1-Score  (COCO-based): 0.559\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"### YOLOv12 Nano (Jetson-Simulated) Accuracy Metrics\\n\")\n",
    "\n",
    "# ---------------------------\n",
    "# 1. mAP metrics\n",
    "# ---------------------------\n",
    "mAP_50_95 = coco_eval_yolo12_jetson.stats[0]     # AP@[0.50:0.95]\n",
    "mAP_50    = coco_eval_yolo12_jetson.stats[1]     # AP@0.50\n",
    "\n",
    "print(f\"mAP@50:95: {mAP_50_95:.3f}\")\n",
    "print(f\"mAP@50:    {mAP_50:.3f}\\n\")\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Precision / Recall from COCOeval\n",
    "# ---------------------------\n",
    "precision = coco_eval_yolo12_jetson.eval['precision']   # precision[IoU, recall, class, area, maxDets]\n",
    "\n",
    "# IoU index 0 = IoU=0.50, area=all, maxDets=100 (index=2)\n",
    "prec_valid = precision[0, :, :, 0, 2]\n",
    "prec_valid = prec_valid[prec_valid > -1]\n",
    "prec_mean = np.mean(prec_valid)\n",
    "\n",
    "recall = coco_eval_yolo12_jetson.eval['recall']         # recall[IoU, class, area, maxDets]\n",
    "rec_valid = recall[0, :, 0, 2]\n",
    "rec_valid = rec_valid[rec_valid > -1]\n",
    "rec_mean = np.mean(rec_valid)\n",
    "\n",
    "# ---------------------------\n",
    "# 3. F1-score\n",
    "# ---------------------------\n",
    "if prec_mean + rec_mean == 0:\n",
    "    f1 = 0\n",
    "else:\n",
    "    f1 = 2 * (prec_mean * rec_mean) / (prec_mean + rec_mean)\n",
    "\n",
    "print(f\"Precision (COCO-based): {prec_mean:.3f}\")\n",
    "print(f\"Recall    (COCO-based): {rec_mean:.3f}\")\n",
    "print(f\"F1-Score  (COCO-based): {f1:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1398467f-4e9a-4e24-81f1-25a2c4481af2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YOLOv12 Env",
   "language": "python",
   "name": "yolov12-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

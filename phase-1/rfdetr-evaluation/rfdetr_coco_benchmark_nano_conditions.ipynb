{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb6ec7d6-9faf-48a9-a5e5-c26eb92d2338",
   "metadata": {},
   "source": [
    "# RF-DETR COCO Benchmark\n",
    "\n",
    "### Setup Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11c65b14-3cb4-4f4a-a41d-07efec240d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CPU Cores: 12\n",
      "CUDA/GPU available: True\n",
      "CUDA version: 12.1\n",
      "GPU name: NVIDIA GeForce GTX 1660 Ti\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import psutil\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "import fiftyone.utils.torch as fout\n",
    "from fiftyone import ViewField as F\n",
    "\n",
    "from rfdetr import RFDETRBase\n",
    "from rfdetr.util.coco_classes import COCO_CLASSES\n",
    "from rfdetr.util.metrics import MetricsPlotSink\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CPU Cores: {psutil.cpu_count(logical=True)}\")\n",
    "\n",
    "print(\"CUDA/GPU available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441ee22e-8fe2-4e72-978c-44827e432a20",
   "metadata": {},
   "source": [
    "### Configure Local COCO Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b96b4ed-2eb4-49d8-b7ea-54a5dce78171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images path: C:\\object-identification-uav-camera\\phase-1\\coco-dataset\\coco-2017\\validation\\data\n",
      "Annotation file: C:\\object-identification-uav-camera\\phase-1\\coco-dataset\\coco-2017\\validation\\labels.json\n",
      "Images found: 3125\n"
     ]
    }
   ],
   "source": [
    "COCO_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"coco-dataset\", \"coco-2017\"))\n",
    "\n",
    "VAL_IMAGES = os.path.join(COCO_ROOT, \"validation\", \"data\")\n",
    "VAL_ANN = os.path.join(COCO_ROOT, \"validation\", \"labels.json\")\n",
    "\n",
    "print(\"Images path:\", VAL_IMAGES)\n",
    "print(\"Annotation file:\", VAL_ANN)\n",
    "print(\"Images found:\", len(os.listdir(VAL_IMAGES)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754a76dc-c19d-4e22-a3be-ed1476f62664",
   "metadata": {},
   "source": [
    "### Load COCO Dataset in FiftyOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ee70ba4-4a5e-448a-b4f8-8a669b3cf60a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:5151/?notebook=True&subscription=0f647a4e-a7b0-4a99-a5f0-2a5956faeb48\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x257d7b4ed70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "\n",
    "dataset = fo.load_dataset(\"coco-val-local\")\n",
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c34c3e8-60f2-4540-8536-fa82d2092ff3",
   "metadata": {},
   "source": [
    "### Initialize Nano Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4a4f280-44ce-4fe4-8036-adac2faadfde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a different number of positional encodings than DINOv2, which means we're not loading DINOv2 backbone weights. This is not a problem if finetuning a pretrained RF-DETR model.\n",
      "Using patch size 16 instead of 14, which means we're not loading DINOv2 backbone weights. This is not a problem if finetuning a pretrained RF-DETR model.\n",
      "Loading pretrain weights\n",
      "Initialized RF-DETR Nano model.\n"
     ]
    }
   ],
   "source": [
    "from rfdetr import RFDETRNano\n",
    "model_nano = RFDETRNano()\n",
    "print(\"Initialized RF-DETR Nano model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946e40ba-50cc-47b8-bf99-0c32419a85cb",
   "metadata": {},
   "source": [
    "### Jetson Simulation Setup Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1db83f35-086d-430e-92f7-46b7978840ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enabling Jetson Orin Nano 8GB simulation constraints...\n",
      "\n",
      "Disabled cuDNN fast algorithms & TF32.\n",
      "CPU threads limited to 2 (Jetson-like).\n",
      "Added 4ms I/O latency per image.\n",
      "Added memory bandwidth stall of 0.8ms.\n",
      "Added 3ms GPU stall per inference (Jetson compute speed).\n",
      "GPU VRAM restricted to ~80% of your card (Jetson-equivalent usable memory).\n",
      "\n",
      "Jetson Simulation Mode READY.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Jetson Orin Nano 8GB Simulation Mode\n",
    "# ============================\n",
    "\n",
    "print(\"\\nEnabling Jetson Orin Nano 8GB simulation constraints...\\n\")\n",
    "\n",
    "# ---- 1. Disable cuDNN fast paths (Jetson uses slower kernels) ----\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "torch.backends.cudnn.allow_tf32 = False\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "print(\"Disabled cuDNN fast algorithms & TF32.\")\n",
    "\n",
    "# ---- 2. Limit CPU parallelism ----\n",
    "import os\n",
    "torch.set_num_threads(2)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"2\"\n",
    "print(\"CPU threads limited to 2 (Jetson-like).\")\n",
    "\n",
    "# ---- 3. I/O latency to mimic Jetson eMMC/SD card ----\n",
    "IO_LATENCY = 0.004  # 4 ms\n",
    "print(\"Added 4ms I/O latency per image.\")\n",
    "\n",
    "# ---- 4. Simulate Jetson memory bandwidth ----\n",
    "BANDWIDTH_LATENCY = 0.0008  # 0.8 ms\n",
    "print(\"Added memory bandwidth stall of 0.8ms.\")\n",
    "\n",
    "# ---- 5. Simulated GPU compute stall ----\n",
    "# Jetson Orin Nano runs ~2–4× slower than GTX 1660 Ti for transformer models\n",
    "GPU_STALL = 0.003  # 3 ms (tuneable)\n",
    "print(\"Added 3ms GPU stall per inference (Jetson compute speed).\")\n",
    "\n",
    "# ---- 6. Constrain VRAM usage ----\n",
    "torch.cuda.set_per_process_memory_fraction(0.80)\n",
    "print(\"GPU VRAM restricted to ~80% of your card (Jetson-equivalent usable memory).\")\n",
    "\n",
    "print(\"\\nJetson Simulation Mode READY.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b75ad7-a1c1-419a-8053-ed0e3c8912be",
   "metadata": {},
   "source": [
    "### Inference Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dca9d133-e5fe-42a5-8317-5b357af27f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Jetson-simulated inference on validation images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3125/3125 [04:32<00:00, 11.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inference complete (Jetson simulated).\n"
     ]
    }
   ],
   "source": [
    "print(\"Running Jetson-simulated inference on validation images...\")\n",
    "\n",
    "preds_json_nano_jetson = []\n",
    "image_filenames = os.listdir(VAL_IMAGES)\n",
    "\n",
    "with open(VAL_ANN, 'r') as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "image_id_map = {img[\"file_name\"]: img[\"id\"] for img in coco_data[\"images\"]}\n",
    "\n",
    "for filename in tqdm(image_filenames):\n",
    "    # Jetson storage bottleneck\n",
    "    time.sleep(IO_LATENCY)\n",
    "\n",
    "    img_path = os.path.join(VAL_IMAGES, filename)\n",
    "\n",
    "    # Load but DO NOT resize (important!)\n",
    "    with Image.open(img_path) as im:\n",
    "        if im.mode != \"RGB\":\n",
    "            im = im.convert(\"RGB\")\n",
    "        temp_path = \"temp_rgb_image.jpg\"\n",
    "        im.save(temp_path)\n",
    "\n",
    "    img_path_for_model = temp_path\n",
    "\n",
    "    # Jetson memory bandwidth bottleneck\n",
    "    time.sleep(BANDWIDTH_LATENCY)\n",
    "\n",
    "    # Jetson GPU compute bottleneck\n",
    "    time.sleep(GPU_STALL)\n",
    "\n",
    "    # Inference\n",
    "    det = model_nano.predict(img_path_for_model, threshold=0.001)\n",
    "\n",
    "    image_id = image_id_map[filename]\n",
    "\n",
    "    boxes = det.xyxy\n",
    "    scores = det.confidence\n",
    "    classes = det.class_id\n",
    "\n",
    "    for box, score, cls in zip(boxes, scores, classes):\n",
    "        x1, y1, x2, y2 = box.tolist()\n",
    "        w = x2 - x1\n",
    "        h = y2 - y1\n",
    "\n",
    "        preds_json_nano_jetson.append({\n",
    "            \"image_id\": image_id,\n",
    "            \"category_id\": int(cls),\n",
    "            \"score\": float(score),\n",
    "            \"bbox\": [float(x1), float(y1), float(w), float(h)]\n",
    "        })\n",
    "\n",
    "with open(\"predictions_nano_jetson.json\", \"w\") as f:\n",
    "    json.dump(preds_json_nano_jetson, f)\n",
    "\n",
    "print(\"\\nInference complete (Jetson simulated).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c711b6-1ddb-4c62-80f5-0c6a3e66edd5",
   "metadata": {},
   "source": [
    "### COCO Evaluation for Nano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba279b32-669c-4dbd-87c3-f7c0820addda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running COCO evaluation on Jetson-simulated predictions...\n",
      "loading annotations into memory...\n",
      "Done (t=0.39s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=6.97s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=43.54s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=10.34s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.428\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.621\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.456\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.234\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.508\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.704\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.342\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.555\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.605\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.374\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.706\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.883\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "print(\"Running COCO evaluation on Jetson-simulated predictions...\")\n",
    "\n",
    "coco_gt = COCO(VAL_ANN)\n",
    "coco_dt_nano_jetson = coco_gt.loadRes(\"predictions_nano_jetson.json\")\n",
    "\n",
    "coco_eval_nano_jetson = COCOeval(coco_gt, coco_dt_nano_jetson, \"bbox\")\n",
    "coco_eval_nano_jetson.evaluate()\n",
    "coco_eval_nano_jetson.accumulate()\n",
    "coco_eval_nano_jetson.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef0b8437-837d-4aac-a389-06ae6ea134f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Jetson-Simulated Nano Model Accuracy Metrics\n",
      "\n",
      "mAP@50:95: 0.428\n",
      "mAP@50:    0.621\n",
      "Precision (COCO-based): 0.621\n",
      "Recall    (COCO-based): 0.832\n",
      "F1-Score  (COCO-based): 0.712\n"
     ]
    }
   ],
   "source": [
    "print(\"### Jetson-Simulated Nano Model Accuracy Metrics\\n\")\n",
    "\n",
    "print(f\"mAP@50:95: {coco_eval_nano_jetson.stats[0]:.3f}\")\n",
    "print(f\"mAP@50:    {coco_eval_nano_jetson.stats[1]:.3f}\")\n",
    "\n",
    "precision = coco_eval_nano_jetson.eval['precision']\n",
    "recall = coco_eval_nano_jetson.eval['recall']\n",
    "\n",
    "# IoU=0.50, area=all, maxDets=100\n",
    "prec_valid = precision[0, :, :, 0, 2]\n",
    "prec_valid = prec_valid[prec_valid > -1]\n",
    "prec_mean = np.mean(prec_valid)\n",
    "\n",
    "rec_valid = recall[0, :, 0, 2]\n",
    "rec_valid = rec_valid[rec_valid > -1]\n",
    "rec_mean = np.mean(rec_valid)\n",
    "\n",
    "if prec_mean + rec_mean == 0:\n",
    "    f1 = 0\n",
    "else:\n",
    "    f1 = 2 * (prec_mean * rec_mean) / (prec_mean + rec_mean)\n",
    "\n",
    "print(f\"Precision (COCO-based): {prec_mean:.3f}\")\n",
    "print(f\"Recall    (COCO-based): {rec_mean:.3f}\")\n",
    "print(f\"F1-Score  (COCO-based): {f1:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RF-DETR Env",
   "language": "python",
   "name": "rfdetr-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

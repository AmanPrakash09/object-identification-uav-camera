{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb6ec7d6-9faf-48a9-a5e5-c26eb92d2338",
   "metadata": {},
   "source": [
    "# RF-DETR COCO Benchmark\n",
    "\n",
    "### Setup Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11c65b14-3cb4-4f4a-a41d-07efec240d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.2.2+cpu\n",
      "GPU Available: False\n",
      "CPU Cores: 12\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import psutil\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "import fiftyone.utils.torch as fout\n",
    "from fiftyone import ViewField as F\n",
    "\n",
    "from rfdetr import RFDETRBase\n",
    "from rfdetr.util.coco_classes import COCO_CLASSES\n",
    "from rfdetr.util.metrics import MetricsPlotSink\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
    "print(f\"CPU Cores: {psutil.cpu_count(logical=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441ee22e-8fe2-4e72-978c-44827e432a20",
   "metadata": {},
   "source": [
    "### Configure Local COCO Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b96b4ed-2eb4-49d8-b7ea-54a5dce78171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images path: C:\\object-identification-uav-camera\\phase-1\\coco-dataset\\coco-2017\\validation\\data\n",
      "Annotation file: C:\\object-identification-uav-camera\\phase-1\\coco-dataset\\coco-2017\\validation\\labels.json\n",
      "Images found: 3125\n"
     ]
    }
   ],
   "source": [
    "COCO_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"coco-dataset\", \"coco-2017\"))\n",
    "\n",
    "VAL_IMAGES = os.path.join(COCO_ROOT, \"validation\", \"data\")\n",
    "VAL_ANN = os.path.join(COCO_ROOT, \"validation\", \"labels.json\")\n",
    "\n",
    "print(\"Images path:\", VAL_IMAGES)\n",
    "print(\"Annotation file:\", VAL_ANN)\n",
    "print(\"Images found:\", len(os.listdir(VAL_IMAGES)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754a76dc-c19d-4e22-a3be-ed1476f62664",
   "metadata": {},
   "source": [
    "### Load COCO Dataset in FiftyOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ee70ba4-4a5e-448a-b4f8-8a669b3cf60a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:5151/?notebook=True&subscription=fff93959-85c2-4598-9e7d-bde65b0e636b\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1c534c6b520>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "\n",
    "dataset = fo.load_dataset(\"coco-val-local\")\n",
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83662ed-d10e-4014-8dae-c5aa30ce045c",
   "metadata": {},
   "source": [
    "### Initialize Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcc013fa-c564-49eb-b2e9-cefb13f01202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrain weights\n",
      "Initialized RFDETRBase (official).\n"
     ]
    }
   ],
   "source": [
    "model = RFDETRBase()\n",
    "print(\"Initialized RFDETRBase (official).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aa580a-f18e-494d-a479-b735a4b6273f",
   "metadata": {},
   "source": [
    "### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a96ce18-a8fe-405a-9b56-c01b8536c9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model is not optimized for inference. Latency may be higher than expected. You can optimize the model for inference by calling model.optimize_for_inference().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction output for 1 image:\n",
      "Detections(xyxy=array([[  5.5638456, 166.15982  , 154.83444  , 262.77823  ],\n",
      "       [415.35245  , 156.7585   , 463.1068   , 298.09616  ],\n",
      "       [292.65765  , 218.50575  , 352.791    , 317.1424   ],\n",
      "       [166.46848  , 232.87022  , 186.74416  , 267.03363  ],\n",
      "       [366.27576  , 218.85649  , 418.3539   , 318.808    ],\n",
      "       [550.05505  , 309.32883  , 585.08167  , 400.6922   ],\n",
      "       [230.74385  , 177.14418  , 267.04306  , 213.15543  ],\n",
      "       [383.8396   , 172.25049  , 401.1604   , 207.90234  ],\n",
      "       [409.12643  , 217.53506  , 442.65793  , 306.8642   ],\n",
      "       [462.523    , 353.80615  , 639.7777   , 424.70316  ],\n",
      "       [448.96915  , 121.108284 , 461.03314  , 141.85272  ],\n",
      "       [318.941    , 225.45256  , 449.36572  , 318.76144  ],\n",
      "       [339.7693   , 176.45566  , 368.3755   , 222.00975  ]],\n",
      "      dtype=float32), mask=None, confidence=array([0.94458145, 0.8771516 , 0.8583023 , 0.8088513 , 0.8056688 ,\n",
      "       0.7526451 , 0.73157495, 0.6774858 , 0.6713647 , 0.6596565 ,\n",
      "       0.55812895, 0.5489757 , 0.5116978 ], dtype=float32), class_id=array([72,  1, 62, 86, 62, 86, 64,  1, 62, 67, 85, 67, 64], dtype=int64), tracker_id=None, data={})\n",
      "Type: <class 'supervision.detection.core.Detections'>\n",
      "First element: Detections(xyxy=array([[  5.5638456, 166.15982  , 154.83444  , 262.77823  ]],\n",
      "      dtype=float32), mask=None, confidence=array([0.94458145], dtype=float32), class_id=array([72], dtype=int64), tracker_id=None, data={})\n",
      "Type of first element: <class 'supervision.detection.core.Detections'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3550.)\n"
     ]
    }
   ],
   "source": [
    "image_filenames = os.listdir(VAL_IMAGES)\n",
    "sample_path = os.path.join(VAL_IMAGES, image_filenames[0])\n",
    "res = model.predict(sample_path)\n",
    "\n",
    "print(\"Prediction output for 1 image:\")\n",
    "print(res)\n",
    "print(\"Type:\", type(res))\n",
    "\n",
    "if len(res) > 0:\n",
    "    print(\"First element:\", res[0])\n",
    "    print(\"Type of first element:\", type(res[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c0ae27-be2e-441e-b734-9bf8cbfba477",
   "metadata": {},
   "source": [
    "### Inference Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2350a8-3ad2-4c03-bb64-8d3bfcfa4ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference on validation images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▉                                                                                                                                              | 62/3125 [01:10<56:02,  1.10s/it]"
     ]
    }
   ],
   "source": [
    "preds_json = []\n",
    "image_filenames = os.listdir(VAL_IMAGES)\n",
    "\n",
    "with open(VAL_ANN, 'r') as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "image_id_map = {img[\"file_name\"]: img[\"id\"] for img in coco_data[\"images\"]}\n",
    "\n",
    "print(\"Running inference on validation images...\")\n",
    "\n",
    "for filename in tqdm(image_filenames):\n",
    "    img_path = os.path.join(VAL_IMAGES, filename)\n",
    "\n",
    "    # --- FIX: Ensure RGB ---\n",
    "    with Image.open(img_path) as im:\n",
    "        if im.mode != \"RGB\":\n",
    "            im = im.convert(\"RGB\")\n",
    "        temp_path = \"temp_rgb_image.jpg\"\n",
    "        im.save(temp_path)\n",
    "        img_path_for_model = temp_path\n",
    "    # ------------------------\n",
    "\n",
    "    det = model.predict(img_path_for_model, threshold=0.001)\n",
    "\n",
    "    image_id = image_id_map[filename]\n",
    "\n",
    "    boxes = det.xyxy\n",
    "    scores = det.confidence\n",
    "    classes = det.class_id\n",
    "\n",
    "    for box, score, cls in zip(boxes, scores, classes):\n",
    "        x1, y1, x2, y2 = box.tolist()\n",
    "        w = x2 - x1\n",
    "        h = y2 - y1\n",
    "\n",
    "        preds_json.append({\n",
    "            \"image_id\": image_id,\n",
    "            \"category_id\": int(cls),\n",
    "            \"score\": float(score),\n",
    "            \"bbox\": [float(x1), float(y1), float(w), float(h)]\n",
    "        })\n",
    "\n",
    "with open(\"predictions.json\", \"w\") as f:\n",
    "    json.dump(preds_json, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2f00a1-94bd-4360-80a0-0104407f234e",
   "metadata": {},
   "source": [
    "### COCO Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93252d52-6d05-426d-8a01-f619a96f4e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "coco_gt = COCO(VAL_ANN)\n",
    "coco_dt = coco_gt.loadRes(\"predictions.json\")\n",
    "\n",
    "coco_eval = COCOeval(coco_gt, coco_dt, \"bbox\")\n",
    "coco_eval.evaluate()\n",
    "coco_eval.accumulate()\n",
    "coco_eval.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702a5c5a-9a46-4c4b-bb9e-aa0ffe92d120",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"### Accuracy Metrics of RF-DETR Base Model\\n\")\n",
    "\n",
    "# ---------------------------\n",
    "# 1. mAP metrics\n",
    "# ---------------------------\n",
    "mAP_50_95 = coco_eval.stats[0]     # AP@[0.50:0.95]\n",
    "mAP_50    = coco_eval.stats[1]     # AP@0.50\n",
    "\n",
    "print(f\"mAP@50:95: {mAP_50_95:.3f}\")\n",
    "print(f\"mAP@50:    {mAP_50:.3f}\\n\")\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Precision / Recall from COCOeval\n",
    "# ---------------------------\n",
    "# COCOeval stores precision as:\n",
    "# precision[IoU, recall, class, area, maxDets]\n",
    "precision = coco_eval.eval['precision']\n",
    "\n",
    "# Use:\n",
    "# IoU = 0 (0.50 IoU)\n",
    "# class = 0:80 (average)\n",
    "# area = 0 (all)\n",
    "# maxDets = 2 (100 detections)\n",
    "\n",
    "# Extract valid values and average across classes/IoUs\n",
    "prec_valid = precision[0, :, :, 0, 2]   # IoU=0.50, area=all, maxDet=100\n",
    "prec_valid = prec_valid[prec_valid > -1]  # remove invalid entries\n",
    "prec_mean = np.mean(prec_valid)\n",
    "\n",
    "# Recall values:\n",
    "recall = coco_eval.eval['recall']   # recall[IoU, class, area, maxDets]\n",
    "rec_valid = recall[0, :, 0, 2]      # IoU=0.50, area=all, maxDets=100\n",
    "rec_valid = rec_valid[rec_valid > -1]\n",
    "rec_mean = np.mean(rec_valid)\n",
    "\n",
    "# ---------------------------\n",
    "# 3. F1-score from COCO PR\n",
    "# ---------------------------\n",
    "if prec_mean + rec_mean == 0:\n",
    "    f1 = 0\n",
    "else:\n",
    "    f1 = 2 * (prec_mean * rec_mean) / (prec_mean + rec_mean)\n",
    "\n",
    "print(f\"Precision (COCO-based): {prec_mean:.3f}\")\n",
    "print(f\"Recall    (COCO-based): {rec_mean:.3f}\")\n",
    "print(f\"F1-Score  (COCO-based): {f1:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c34c3e8-60f2-4540-8536-fa82d2092ff3",
   "metadata": {},
   "source": [
    "## Repeat Steps for RF-DETR Nano\n",
    "### Initialize Nano Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a4f280-44ce-4fe4-8036-adac2faadfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rfdetr import RFDETRNano\n",
    "model_nano = RFDETRNano()\n",
    "print(\"Initialized RF-DETR Nano model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b75ad7-a1c1-419a-8053-ed0e3c8912be",
   "metadata": {},
   "source": [
    "### Inference Loop for Nano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca9d133-e5fe-42a5-8317-5b357af27f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_json_nano = []\n",
    "image_filenames = os.listdir(VAL_IMAGES)\n",
    "\n",
    "with open(VAL_ANN, 'r') as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "image_id_map = {img[\"file_name\"]: img[\"id\"] for img in coco_data[\"images\"]}\n",
    "\n",
    "print(\"Running inference on validation images (Nano model)...\")\n",
    "\n",
    "for filename in tqdm(image_filenames):\n",
    "    img_path = os.path.join(VAL_IMAGES, filename)\n",
    "\n",
    "    # Ensure RGB\n",
    "    with Image.open(img_path) as im:\n",
    "        if im.mode != \"RGB\":\n",
    "            im = im.convert(\"RGB\")\n",
    "        temp_path = \"temp_rgb_image.jpg\"\n",
    "        im.save(temp_path)\n",
    "        img_path_for_model = temp_path\n",
    "\n",
    "    det = model_nano.predict(img_path_for_model, threshold=0.001)\n",
    "\n",
    "    image_id = image_id_map[filename]\n",
    "\n",
    "    boxes = det.xyxy\n",
    "    scores = det.confidence\n",
    "    classes = det.class_id\n",
    "\n",
    "    for box, score, cls in zip(boxes, scores, classes):\n",
    "        x1, y1, x2, y2 = box.tolist()\n",
    "        w = x2 - x1\n",
    "        h = y2 - y1\n",
    "\n",
    "        preds_json_nano.append({\n",
    "            \"image_id\": image_id,\n",
    "            \"category_id\": int(cls),\n",
    "            \"score\": float(score),\n",
    "            \"bbox\": [float(x1), float(y1), float(w), float(h)]\n",
    "        })\n",
    "\n",
    "with open(\"predictions_nano.json\", \"w\") as f:\n",
    "    json.dump(preds_json_nano, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c711b6-1ddb-4c62-80f5-0c6a3e66edd5",
   "metadata": {},
   "source": [
    "### COCO Evaluation for Nano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba279b32-669c-4dbd-87c3-f7c0820addda",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_gt = COCO(VAL_ANN)\n",
    "coco_dt_nano = coco_gt.loadRes(\"predictions_nano.json\")\n",
    "\n",
    "coco_eval_nano = COCOeval(coco_gt, coco_dt_nano, \"bbox\")\n",
    "coco_eval_nano.evaluate()\n",
    "coco_eval_nano.accumulate()\n",
    "coco_eval_nano.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0b8437-837d-4aac-a389-06ae6ea134f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = coco_eval_nano.eval['precision']\n",
    "recall = coco_eval_nano.eval['recall']\n",
    "\n",
    "# Extract IoU=0.50, area=all, maxDets=100\n",
    "prec_valid = precision[0, :, :, 0, 2]\n",
    "prec_valid = prec_valid[prec_valid > -1]\n",
    "prec_mean = np.mean(prec_valid)\n",
    "\n",
    "rec_valid = recall[0, :, 0, 2]\n",
    "rec_valid = rec_valid[rec_valid > -1]\n",
    "rec_mean = np.mean(rec_valid)\n",
    "\n",
    "f1 = 0 if (prec_mean + rec_mean == 0) else 2 * (prec_mean * rec_mean) / (prec_mean + rec_mean)\n",
    "\n",
    "print(\"### Nano Model Accuracy Metrics\\n\")\n",
    "print(f\"mAP@50:95: {coco_eval_nano.stats[0]:.3f}\")\n",
    "print(f\"mAP@50:    {coco_eval_nano.stats[1]:.3f}\")\n",
    "print(f\"Precision (COCO-based): {prec_mean:.3f}\")\n",
    "print(f\"Recall    (COCO-based): {rec_mean:.3f}\")\n",
    "print(f\"F1-Score  (COCO-based): {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb25f16f-21db-4c22-adb3-6fa86775b6cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RF-DETR Env",
   "language": "python",
   "name": "rfdetr-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
